{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook runs preparation for SeismicGeometry tests and SeismicGeometry tests for different cube formats\n",
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "import glob\n",
    "import json\n",
    "import nbformat\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from py.path import local\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "sys.path.append('../..') # for running py-script\n",
    "sys.path.append('../../..') # for running this notebook directly\n",
    "from seismiqb.batchflow.utils_notebook import run_notebook\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults for run directly from this notebook\n",
    "# DATESTAMP = date.today().strftime(\"%Y-%m-%d\")\n",
    "# NOTEBOOKS_DIR = './'\n",
    "# DROP_EXTRA_FILES = True # drop files reffering to successful tests\n",
    "# SHOW_TEST_ERROR_INFO = True # whether to show info about a test case with an error (if an error exists)\n",
    "# SAVING_DIR = './geometry_test_files/'\n",
    "# GITHUB_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and parameters:\n",
    "CUBE_NAME = f'test_cube_{DATESTAMP}.sgy'\n",
    "FORMATS = ['sgy', 'hdf5', 'qhdf5', 'blosc', 'qblosc']\n",
    "\n",
    "# Storage preparation:\n",
    "# The `tmp` dir contains cube files: cube in different formats and meta\n",
    "# The `notebooks` dir contains notebooks results (notebooks copies with outputs)\n",
    "if GITHUB_MODE:\n",
    "    _ = SAVING_DIR.mkdir(\"notebooks\")\n",
    "    _ = SAVING_DIR.mkdir(\"tmp\")\n",
    "\n",
    "else:\n",
    "    !rm -rf {SAVING_DIR + 'tmp/'}\n",
    "    !rm -rf {SAVING_DIR + 'notebooks/'}\n",
    "    !mkdir {SAVING_DIR + 'tmp/'}\n",
    "    !mkdir {SAVING_DIR + 'notebooks/'}\n",
    "\n",
    "# if previous run failed than we need to delete corresponding timings\n",
    "failed_timings_file = glob.glob(str(SAVING_DIR) + 'timings*fail*.json')\n",
    "\n",
    "for file in failed_timings_file:\n",
    "    os.remove(file)\n",
    "\n",
    "msg = DATESTAMP + '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the notebook with preparation for tests.\n",
    "# It contains: data creation, data loading checking and cube conversion into different formats\n",
    "out_path_ipynb = os.path.join(SAVING_DIR, f'notebooks/geometry_test_preparation_out_{DATESTAMP}.ipynb')\n",
    "\n",
    "exec_info = run_notebook(\n",
    "    path=os.path.join(NOTEBOOKS_DIR, 'geometry_test_preparation.ipynb'),\n",
    "    nb_kwargs={\n",
    "        'CUBE_NAME': CUBE_NAME,\n",
    "        'CUBE_SHAPE': (1000, 200, 400),\n",
    "        'SEED': 42,\n",
    "        'DATESTAMP': DATESTAMP,\n",
    "        'SAVING_DIR': SAVING_DIR\n",
    "    },\n",
    "    insert_pos=1,\n",
    "    out_path_ipynb=out_path_ipynb,\n",
    "    display_links=False\n",
    ")\n",
    "\n",
    "if exec_info is True:\n",
    "    msg += 'Data was successfully prepared.\\n'\n",
    "else:\n",
    "    msg += f'An ERROR occured in cell number {exec_info}:\\n{out_path_ipynb}\\n'\n",
    "    \n",
    "    if SHOW_TEST_ERROR_INFO:\n",
    "        # Add error traceback into the message\n",
    "        out_notebook = nbformat.read(out_path_ipynb, as_version=4)\n",
    "        cell_info = out_notebook['cells'][exec_info + 1] # plus one because we inserted an additional cell\n",
    "\n",
    "        for output in cell_info['outputs']:\n",
    "                output_type = output.get('output_type', False)\n",
    "\n",
    "                if output_type == 'error':\n",
    "                    current_message += f\"TRACEBACK: \\n {traceback}\\n\"\n",
    "                    traceback = output.get('traceback', None)\n",
    "                    for line in traceback:\n",
    "                        current_message += line\n",
    "                    break\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test notebook for the cube in each data format.\n",
    "# It contains: checking data; attributes, slides, crops loading test, data loading timings and visualization tests.\n",
    "timings = {}\n",
    "all_OK = True\n",
    "\n",
    "for f in tqdm(FORMATS):\n",
    "    current_message = ''\n",
    "\n",
    "    # Run and save the test notebook\n",
    "    out_path_ipynb = os.path.join(SAVING_DIR, f'notebooks/geometry_test_data_format_{f.upper()}_out_{DATESTAMP}.ipynb')\n",
    "\n",
    "    exec_info = run_notebook(\n",
    "        path=os.path.join(NOTEBOOKS_DIR, 'geometry_test_data_format.ipynb'),\n",
    "        nb_kwargs={\n",
    "            'CUBE_NAME': CUBE_NAME.replace('sgy', f),\n",
    "            'TEST_DIR': TEST_DIR,\n",
    "            'N_SLIDE': 1000,\n",
    "            'N_CROP': 300,\n",
    "            'FIGSIZE': (12, 6),\n",
    "            'SEED': 42,\n",
    "            'DATESTAMP': DATESTAMP,\n",
    "            'DROP_EXTRA_FILES': DROP_EXTRA_FILES,\n",
    "            'SAVING_DIR': SAVING_DIR\n",
    "        },\n",
    "        insert_pos=1, \n",
    "        out_path_ipynb=out_path_ipynb,\n",
    "        display_links=False\n",
    "    )\n",
    "    \n",
    "    # Saving logs\n",
    "    if exec_info is True:\n",
    "        with open(os.path.join(SAVING_DIR, f'tmp/timings_{f}_{DATESTAMP}.json'), \"r\") as infile:\n",
    "            timings.update(json.load(infile))\n",
    "\n",
    "        # If everything is OK we can delete the test notebook\n",
    "        if DROP_EXTRA_FILES:\n",
    "            os.remove(out_path_ipynb)\n",
    "\n",
    "        current_message += f'Notebook for {f.upper()} executed correctly and was deleted.\\n'\n",
    "    else:\n",
    "        all_OK = False\n",
    "        current_message += f'An ERROR occured in cell number {exec_info}:\\n'\n",
    "\n",
    "        if SHOW_TEST_ERROR_INFO:\n",
    "            # Get first line in the error cell. It contains comment with a test case.\n",
    "            out_notebook = nbformat.read(out_path_ipynb, as_version=4)\n",
    "            cell_info = out_notebook['cells'][exec_info + 1] # plus one because we inserted an additional cell\n",
    "            first_line = cell_info['source'].split('\\n')[0]\n",
    "\n",
    "            if first_line[0] == '#':\n",
    "                # Prettifyings:\n",
    "                if first_line[-1] == ':':\n",
    "                    first_line = first_line[1:-1]\n",
    "                else:\n",
    "                    first_line = first_line[1:]\n",
    "\n",
    "                current_message += f'Test \\\"{first_line.strip()}\\\" failure in:\\n\\n'\n",
    "            \n",
    "            # And add error traceback into the message\n",
    "            for output in cell_info['outputs']:\n",
    "                output_type = output.get('output_type', False)\n",
    "                \n",
    "                if output_type == 'error':\n",
    "                    current_message += f\"TRACEBACK: \\n\"\n",
    "                    \n",
    "                    traceback = output.get('traceback', None)\n",
    "                    for line in traceback:\n",
    "                        current_message += line\n",
    "                    break\n",
    "\n",
    "\n",
    "        current_message += f'{out_path_ipynb}\\n\\n'\n",
    "\n",
    "    print(current_message)\n",
    "    msg += current_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output\n",
    "print(msg)\n",
    "print(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize timings\n",
    "def plot_ax(dct, unit, title, ax):\n",
    "    bars = ax.bar(dct.keys(), dct.values())\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel('Storage format', fontsize=16)\n",
    "    ax.set_ylabel(unit, fontsize=16)\n",
    "    return ax\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axs[0] = plot_ax(dct={key: value['slide']['wall'] for key, value in timings.items()},\n",
    "                 unit=\"Time, ms\", title=\"Slide loading timings\", ax=axs[0])\n",
    "axs[1] = plot_ax(dct={key: value['crop']['wall'] for key, value in timings.items()},\n",
    "                 unit=\"Time, ms\", title=\"Crop loading timings\", ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump timings and message and remove extra files\n",
    "if all_OK:\n",
    "    timings['state'] = 'OK'\n",
    "\n",
    "    if DROP_EXTRA_FILES:\n",
    "        # Remove old timings\n",
    "        timings_files = glob.glob(os.path.join(str(SAVING_DIR), 'timings*.json'))\n",
    "        for file in timings_files:\n",
    "            os.remove(file)\n",
    "\n",
    "        # Remove dirs with temporary files\n",
    "        !rm -rf {SAVING_DIR + 'tmp/'}\n",
    "        !rm -rf {SAVING_DIR + 'notebooks/'}\n",
    "\n",
    "    timings_file_name = f'timings_{DATESTAMP}.json'   \n",
    "else:\n",
    "    timings['state'] = 'FAIL'\n",
    "    \n",
    "    if DROP_EXTRA_FILES:\n",
    "        # Remove timings for each data format\n",
    "        timings_files = glob.glob(str(SAVING_DIR) + 'tmp/timings*')\n",
    "        for file_name in timings_files:\n",
    "            os.remove(file_name)\n",
    "\n",
    "    timings_file_name = f'timings_fail_{DATESTAMP}.json'\n",
    "\n",
    "    \n",
    "if not GITHUB_MODE:\n",
    "    SAVING_RES_DIR = TEST_DIR\n",
    "else:\n",
    "    SAVING_RES_DIR = SAVING_DIR\n",
    "\n",
    "# Dump timings            \n",
    "with open(os.path.join(SAVING_RES_DIR, timings_file_name), \"w\") as outfile:\n",
    "    json.dump(timings, outfile)\n",
    "\n",
    "# Message: drop old and save new\n",
    "msg_files = glob.glob(os.path.join(str(SAVING_RES_DIR), 'message*.txt'))\n",
    "for file in msg_files:\n",
    "    os.remove(file)\n",
    "\n",
    "with open(os.path.join(SAVING_RES_DIR, f'message_{DATESTAMP}.txt'), \"w\") as outfile:\n",
    "    outfile.write(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
